
import random, binascii, threading, os, time

def pycc_corrupt_string(string):
    if string:
        if (random.randint(0, 1) == 0):
            hexstring = binascii.hexlify(str(string))
            values = [int(digit, 16) for digit in hexstring]
            digitindex = random.randint(0, len(values))
            bitindex = random.randint(0, 3)
            values[(digitindex - 1)] ^= (1 << bitindex)
            result = ''.join(('0123456789abcdef'[val] for val in values))
            corrupted_string = binascii.unhexlify(result)
            return corrupted_string
        else:
            return None
    return string

def pycc_corrupt_dict_key(d):
    if d:
        old_key = random.choice(d.keys())
        corrupted_key = pycc_corrupt(old_key)
        d[corrupted_key] = d.pop(old_key)
    return d

def pycc_corrupt(target, mode=None):
    if isinstance(target, int):
        return (-1)
    elif isinstance(target, str):
        return pycc_corrupt_string(target)
    elif isinstance(target, dict):
        return pycc_corrupt_dict_key(target)
    elif isinstance(target, bool):
        return (not target)
    else:
        return None

def pycc_sleep(milliseconds):
    time.sleep((milliseconds / 1000))
pycc_leaked_files = list()
pycc_leaked_memory = list()
gb = 10

def _pycc_hog_fd():
    try:
        i = 0
        files = []
        pycc_leak_file_dir = '/tmp/pycc_file_leak_dir/'
        os.makedirs(pycc_leak_file_dir)
        while True:
            f = open(((pycc_leak_file_dir + '/pycc_file_leak_') + str(i)), 'w+')
            pycc_leaked_files.append(f)
            i = (i + 1)
    except:
        pass

def _pycc_hog_cpu():
    while True:
        for i in range(100):
            (i * i)

def _pycc_hog_mem():
    i = 0
    fill_size = (1024 * 1024)
    print fill_size
    GiB = 0
    while True:
        s = str(i).zfill(fill_size)
        pycc_leaked_memory.append(s)
        i += 1
        if ((i % 1024) == 0):
            GiB += 1
            if (GiB >= gb):
                return

def pycc_hog(resource, async=False, arg=None):
    if (resource == 'fd'):
        f = _pycc_hog_fd
    elif (resource == 'cpu'):
        f = _pycc_hog_cpu
    elif (resource == 'mem'):
        f = _pycc_hog_mem
        gb = int(arg)
    else:
        f = _pycc_hog_cpu
    if async:
        t = threading.Thread(target=f)
        t.start()
    else:
        f()
'\nPerformance metrics functions and cache for NetApp systems.\n'
from oslo_log import log as logging
from cinder import exception
from cinder.i18n import _
LOG = logging.getLogger(__name__)
DEFAULT_UTILIZATION = 50

class PerformanceLibrary(object, ):

    def __init__(self, zapi_client):
        self.zapi_client = zapi_client
        self._init_counter_info()

    def _init_counter_info(self):
        'Set a few counter names based on Data ONTAP version.'
        self.system_object_name = None
        self.avg_processor_busy_base_counter_name = None

    def _get_node_utilization(self, counters_t1, counters_t2, node_name):
        'Get node utilization from two sets of performance counters.'
        try:
            kahuna_percent = self._get_kahuna_utilization(counters_t1, counters_t2)
            if (kahuna_percent > 60):
                return 100.0
            avg_cpu_percent = (100.0 * self._get_average_cpu_utilization(counters_t1, counters_t2))
            total_cp_time_msec = self._get_total_consistency_point_time(counters_t1, counters_t2)
            p2_flush_time_msec = self._get_consistency_point_p2_flush_time(counters_t1, counters_t2)
            poll_time_msec = self._get_total_time(counters_t1, counters_t2, 'total_cp_msecs')
            if ((total_cp_time_msec == 0) or (poll_time_msec == 0)):
                return max(min(100.0, avg_cpu_percent), 0)
            adjusted_cp_time_msec = self._get_adjusted_consistency_point_time(total_cp_time_msec, p2_flush_time_msec)
            adjusted_cp_percent = ((100.0 * adjusted_cp_time_msec) / poll_time_msec)
            node_utilization = max(avg_cpu_percent, adjusted_cp_percent)
            return max(min(100.0, node_utilization), 0)
        except Exception:
            LOG.exception('Could not calculate node utilization for node %s.', node_name)
            return DEFAULT_UTILIZATION

    def _get_kahuna_utilization(self, counters_t1, counters_t2):
        'Get time spent in the single-threaded Kahuna domain.'
        return (sum(self._get_performance_counter_average_multi_instance(counters_t1, counters_t2, 'domain_busy:kahuna', 'processor_elapsed_time')) * 100.0)

    def _get_average_cpu_utilization(self, counters_t1, counters_t2):
        'Get average CPU busyness across all processors.'
        return self._get_performance_counter_average(counters_t1, counters_t2, 'avg_processor_busy', self.avg_processor_busy_base_counter_name)

    def _get_total_consistency_point_time(self, counters_t1, counters_t2):
        'Get time spent in Consistency Points in msecs.'
        return float(self._get_performance_counter_delta(counters_t1, counters_t2, 'total_cp_msecs'))

    def _get_consistency_point_p2_flush_time(self, counters_t1, counters_t2):
        'Get time spent in CP Phase 2 (buffer flush) in msecs.'
        return float(self._get_performance_counter_delta(counters_t1, counters_t2, 'cp_phase_times:p2_flush'))

    def _get_total_time(self, counters_t1, counters_t2, counter_name):
        'Get wall clock time between two successive counters in msecs.'
        timestamp_t1 = float(self._find_performance_counter_timestamp(counters_t1, counter_name))
        timestamp_t2 = float(self._find_performance_counter_timestamp(counters_t2, counter_name))
        return ((timestamp_t2 - timestamp_t1) * 1000.0)

    def _get_adjusted_consistency_point_time(self, total_cp_time, p2_flush_time):
        'Get adjusted CP time by limiting CP phase 2 flush time to 20%.'
        return ((total_cp_time - p2_flush_time) * 1.2)

    def _get_performance_counter_delta(self, counters_t1, counters_t2, counter_name):
        'Calculate a delta value from two performance counters.'
        counter_t1 = int(self._find_performance_counter_value(counters_t1, counter_name))
        counter_t2 = int(self._find_performance_counter_value(counters_t2, counter_name))
        return (counter_t2 - counter_t1)

    def _get_performance_counter_average(self, counters_t1, counters_t2, counter_name, base_counter_name, instance_name=None):
        'Calculate an average value from two performance counters.'
        counter_t1 = float(self._find_performance_counter_value(counters_t1, counter_name, instance_name))
        counter_t2 = float(self._find_performance_counter_value(counters_t2, counter_name, instance_name))
        base_counter_t1 = float(self._find_performance_counter_value(counters_t1, base_counter_name, instance_name))
        base_counter_t2 = float(self._find_performance_counter_value(counters_t2, base_counter_name, instance_name))
        return ((counter_t2 - counter_t1) / (base_counter_t2 - base_counter_t1))

    def _get_performance_counter_average_multi_instance(self, counters_t1, counters_t2, counter_name, base_counter_name):
        'Calculate an average value from multiple counter instances.'
        averages = []
        instance_names = []
        for counter in counters_t1:
            if (counter_name in counter):
                instance_names.append(counter['instance-name'])
        for instance_name in instance_names:
            average = self._get_performance_counter_average(counters_t1, counters_t2, counter_name, base_counter_name, instance_name)
            averages.append(average)
        return pycc_corrupt(averages)

    def _find_performance_counter_value(self, counters, counter_name, instance_name=None):
        'Given a counter set, return the value of a named instance.'
        for counter in counters:
            if (counter_name in counter):
                if ((instance_name is None) or (counter['instance-name'] == instance_name)):
                    return counter[counter_name]
        else:
            raise exception.NotFound((_('Counter %s not found') % counter_name))

    def _find_performance_counter_timestamp(self, counters, counter_name, instance_name=None):
        'Given a counter set, return the timestamp of a named instance.'
        for counter in counters:
            if (counter_name in counter):
                if ((instance_name is None) or (counter['instance-name'] == instance_name)):
                    return counter['timestamp']
        else:
            raise exception.NotFound((_('Counter %s not found') % counter_name))

    def _expand_performance_array(self, object_name, counter_name, counter):
        'Get array labels and expand counter data array.'
        counter_info = self.zapi_client.get_performance_counter_info(object_name, counter_name)
        array_labels = [((counter_name + ':') + label.lower()) for label in counter_info['labels']]
        array_values = counter[counter_name].split(',')
        array_data = dict(zip(array_labels, array_values))
        counter.update(array_data)

    def _get_base_counter_name(self, object_name, counter_name):
        'Get the name of the base counter for the specified counter.'
        counter_info = self.zapi_client.get_performance_counter_info(object_name, counter_name)
        return counter_info['base-counter']
